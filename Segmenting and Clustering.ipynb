{"cells": [{"metadata": {"collapsed": true}, "cell_type": "markdown", "source": "# Segmenting and Clustering Neighborhoods in the city of Toronto, Canada"}, {"metadata": {}, "cell_type": "markdown", "source": "The project includes scraping the Wikipedia page for the postal codes of Canada and then process and clean the data for the clustering. The clustering is carried out by K Means and the clusters are plotted using the Folium Library. The Boroughs containing the name 'Toronto' in it are first plotted and then clustered and plotted again"}, {"metadata": {}, "cell_type": "markdown", "source": "## All the 3 tasks of *web scraping, cleaning* and *clustering* are implemented in the same notebook for the ease of evaluation."}, {"metadata": {}, "cell_type": "code", "source": "!pip install beautifulsoup4\n!pip install lxml\nimport requests # library to handle requests\nimport pandas as pd # library for data analsysis\nimport numpy as np # library to handle data in a vectorized manner\nimport random # library for random number generation\n\n#!conda install -c conda-forge geopy --yes \nfrom geopy.geocoders import Nominatim # module to convert an address into latitude and longitude values\n\n# libraries for displaying images\nfrom IPython.display import Image \nfrom IPython.core.display import HTML \n\n\nfrom IPython.display import display_html\nimport pandas as pd\nimport numpy as np\n    \n# tranforming json file into a pandas dataframe library\nfrom pandas.io.json import json_normalize\n\n!conda install -c conda-forge folium=0.5.0 --yes\nimport folium # plotting library\nfrom bs4 import BeautifulSoup\nfrom sklearn.cluster import KMeans\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\n\nprint('Folium installed')\nprint('Libraries imported.')", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Scraping the Wikipedia page for the table of postal codes of Canada"}, {"metadata": {}, "cell_type": "markdown", "source": "BeautifulSoup Library of Python is used for web scraping of table from the Wikipedia. The title of the webpage is printed to check if the page has been scraped successfully or not. Then the table of postal codes of Canada is printed."}, {"metadata": {}, "cell_type": "code", "source": "source = requests.get('https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M').text\nsoup=BeautifulSoup(source,'lxml')\nprint(soup.title)\nfrom IPython.display import display_html\ntab = str(soup.table)\ndisplay_html(tab,raw=True)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### The html table is converted to Pandas DataFrame for cleaning and preprocessing"}, {"metadata": {}, "cell_type": "code", "source": "dfs = pd.read_html(tab)\ndf=dfs[0]\ndf.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Data preprocessing and cleaning"}, {"metadata": {}, "cell_type": "code", "source": "# Dropping the rows where Borough is 'Not assigned'\ndf1 = df[df.Borough != 'Not assigned']\n\n# Combining the neighbourhoods with same Postalcode\ndf2 = df1.groupby(['Postcode','Borough'], sort=False).agg(', '.join)\ndf2.reset_index(inplace=True)\n\n# Replacing the name of the neighbourhoods which are 'Not assigned' with names of Borough\ndf2['Neighbourhood'] = np.where(df2['Neighbourhood'] == 'Not assigned',df2['Borough'], df2['Neighbourhood'])\n\ndf2", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Shape of data frame\ndf2.shape", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Importing the csv file conatining the latitudes and longitudes for various neighbourhoods in Canada"}, {"metadata": {}, "cell_type": "code", "source": "lat_lon = pd.read_csv('https://cocl.us/Geospatial_data')\nlat_lon.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Merging the two tables for getting the Latitudes and Longitudes for various neighbourhoods in Canada"}, {"metadata": {}, "cell_type": "code", "source": "lat_lon.rename(columns={'Postal Code':'Postcode'},inplace=True)\ndf3 = pd.merge(df2,lat_lon,on='Postcode')\ndf3.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### The notebook from here includes the Clustering and the plotting of the neighbourhoods of Canada which contain Toronto in their Borough"}, {"metadata": {}, "cell_type": "markdown", "source": "**Getting all the rows from the data frame which contains Toronto in their Borough.**"}, {"metadata": {}, "cell_type": "code", "source": "df4 = df3[df3['Borough'].str.contains('Toronto',regex=False)]\ndf4", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.7", "language": "python"}, "language_info": {"name": "python", "version": "3.7.10", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}